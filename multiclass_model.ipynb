{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "new_env",
   "display_name": "Python 3.11 (new_env)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from itertools import product\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from itertools import product\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import helper_functions as hf\n",
    "from constants import(\n",
    "    platoon_state_mapping,\n",
    "    side_buckets,\n",
    "    height_buckets,\n",
    "    count_values,\n",
    "    num_clusters,\n",
    "    numerical_features,\n",
    "    pseudo_sample_size,\n",
    "    median_features\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rv_model = joblib.load('rv_model.pkl')\n",
    "gmm_models = hf.load_gmm_models()\n",
    "\n",
    "pitches_df = pd.read_csv('all_pitches.csv')\n",
    "global_means = pd.read_csv('global_means.csv')\n",
    "\n",
    "pitches_df = hf.prepare_data(pitches_df, game_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_class_mapping = {\n",
    "    \"Out\": 0,\n",
    "    \"Error\": 0,\n",
    "    \"Fielderschoice\": 0,\n",
    "    \"Single\": 1,\n",
    "    \"Double\": 2,\n",
    "    \"Triple\": 3,\n",
    "    \"HomeRun\": 4\n",
    "}\n",
    "\n",
    "pitches_df[\"ResultClass\"] = pitches_df[\"PlayResult\"].map(result_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ExitSpeed', 'Angle', 'DirectionBucket']\n",
    "target = 'ResultClass'\n",
    "\n",
    "model_df = pitches_df.dropna(subset=features + [target])\n",
    "\n",
    "X = model_df[features]\n",
    "y = model_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2025-03-11 11:39:15,225] A new study created in memory with name: no-name-4e6ec393-ea05-4ed2-bd4c-49d419d7bc9b\n",
      "[I 2025-03-11 11:39:16,237] Trial 0 finished with value: -0.6308115107255305 and parameters: {'learning_rate': 0.18562485556268069, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.5218859042265322, 'colsample_bytree': 0.7035227314705224, 'lambda': 0.2590617887113503, 'alpha': 0.001242082957942944, 'gamma': 4.755736576810502, 'n_estimators': 50}. Best is trial 0 with value: -0.6308115107255305.\n",
      "[I 2025-03-11 11:39:19,359] Trial 1 finished with value: -0.6128629360002783 and parameters: {'learning_rate': 0.15763320986093884, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7125846218326882, 'colsample_bytree': 0.9439599993456766, 'lambda': 0.01142718718542299, 'alpha': 0.05475907126389026, 'gamma': 0.20498626924271457, 'n_estimators': 140}. Best is trial 0 with value: -0.6308115107255305.\n",
      "[I 2025-03-11 11:39:22,844] Trial 2 finished with value: -0.6135983118207502 and parameters: {'learning_rate': 0.1370509034770082, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.9492180153067408, 'colsample_bytree': 0.8066029797034613, 'lambda': 0.30148731738491297, 'alpha': 0.052404993636069507, 'gamma': 0.829387402796497, 'n_estimators': 156}. Best is trial 0 with value: -0.6308115107255305.\n",
      "[I 2025-03-11 11:39:24,642] Trial 3 finished with value: -0.6334219770163436 and parameters: {'learning_rate': 0.10513084232110954, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6978504149961513, 'colsample_bytree': 0.845190802924688, 'lambda': 0.0032124378333009485, 'alpha': 0.004481048858251602, 'gamma': 2.444704374562327, 'n_estimators': 63}. Best is trial 3 with value: -0.6334219770163436.\n",
      "[I 2025-03-11 11:39:25,956] Trial 4 finished with value: -0.6228034122616469 and parameters: {'learning_rate': 0.2997598668541721, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9803794946451398, 'colsample_bytree': 0.9847079590740488, 'lambda': 0.2504967382224963, 'alpha': 0.001714505495531228, 'gamma': 4.5310829830493535, 'n_estimators': 95}. Best is trial 3 with value: -0.6334219770163436.\n",
      "[I 2025-03-11 11:39:29,874] Trial 5 finished with value: -0.6885741687403973 and parameters: {'learning_rate': 0.07618878270908105, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7454302127994544, 'colsample_bytree': 0.6474015515941403, 'lambda': 0.06431960958261422, 'alpha': 0.007619237094084987, 'gamma': 4.93859966903586, 'n_estimators': 270}. Best is trial 5 with value: -0.6885741687403973.\n",
      "[I 2025-03-11 11:39:35,294] Trial 6 finished with value: -0.6795941887803865 and parameters: {'learning_rate': 0.12291774931511561, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6387326340424311, 'colsample_bytree': 0.644674934751178, 'lambda': 0.009498756171224565, 'alpha': 1.69824502986484, 'gamma': 2.042309921364536, 'n_estimators': 357}. Best is trial 5 with value: -0.6885741687403973.\n",
      "[I 2025-03-11 11:39:38,881] Trial 7 finished with value: -0.6271545203030617 and parameters: {'learning_rate': 0.12369754663702753, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8861328881983974, 'colsample_bytree': 0.9050683029738326, 'lambda': 0.7792899478151649, 'alpha': 1.2437882015752633, 'gamma': 4.38372311297557, 'n_estimators': 303}. Best is trial 5 with value: -0.6885741687403973.\n",
      "[I 2025-03-11 11:39:41,078] Trial 8 finished with value: -0.6147448717379065 and parameters: {'learning_rate': 0.2961218673094379, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.9007248080608318, 'colsample_bytree': 0.9566935952265783, 'lambda': 0.099788001471282, 'alpha': 0.0012810180992516218, 'gamma': 1.6411535886475048, 'n_estimators': 165}. Best is trial 5 with value: -0.6885741687403973.\n",
      "[I 2025-03-11 11:39:42,913] Trial 9 finished with value: -0.7141941371507265 and parameters: {'learning_rate': 0.09620802686246502, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.5721706480642923, 'colsample_bytree': 0.5818927428536431, 'lambda': 0.008200454494627672, 'alpha': 4.246609706758928, 'gamma': 2.647545836580647, 'n_estimators': 105}. Best is trial 9 with value: -0.7141941371507265.\n",
      "[I 2025-03-11 11:39:50,239] Trial 10 finished with value: -0.7282808710697448 and parameters: {'learning_rate': 0.017857266966456883, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.5069498057254872, 'colsample_bytree': 0.5051364846428081, 'lambda': 3.4745862865265513, 'alpha': 9.158196963872214, 'gamma': 3.525520518223261, 'n_estimators': 481}. Best is trial 10 with value: -0.7282808710697448.\n",
      "[I 2025-03-11 11:39:57,597] Trial 11 finished with value: -0.7292075457100389 and parameters: {'learning_rate': 0.017368008608116176, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.5087921455780491, 'colsample_bytree': 0.510442938231924, 'lambda': 8.333136820698732, 'alpha': 9.702703494811825, 'gamma': 3.524430906712688, 'n_estimators': 494}. Best is trial 11 with value: -0.7292075457100389.\n",
      "[I 2025-03-11 11:40:05,253] Trial 12 finished with value: -0.7476195085821928 and parameters: {'learning_rate': 0.013597533082341276, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.5398076070544408, 'colsample_bytree': 0.5178933873703492, 'lambda': 8.17268517647494, 'alpha': 9.670093189112466, 'gamma': 3.5096428828843838, 'n_estimators': 491}. Best is trial 12 with value: -0.7476195085821928.\n",
      "[I 2025-03-11 11:40:12,799] Trial 13 finished with value: -0.7465550215201817 and parameters: {'learning_rate': 0.013606303631447925, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.609053606889383, 'colsample_bytree': 0.5231821900716884, 'lambda': 7.705590174536923, 'alpha': 0.39731900863025826, 'gamma': 3.425664987812418, 'n_estimators': 474}. Best is trial 12 with value: -0.7476195085821928.\n",
      "[I 2025-03-11 11:40:18,801] Trial 14 finished with value: -0.691569048325114 and parameters: {'learning_rate': 0.0424359767667614, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.6162906378025758, 'colsample_bytree': 0.5770293538767302, 'lambda': 1.783808379444626, 'alpha': 0.29829313841409155, 'gamma': 3.4068569013563192, 'n_estimators': 408}. Best is trial 12 with value: -0.7476195085821928.\n",
      "[I 2025-03-11 11:40:23,508] Trial 15 finished with value: -0.6793484678314063 and parameters: {'learning_rate': 0.2283758995516444, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8016158249800336, 'colsample_bytree': 0.5640782749459183, 'lambda': 6.759630036440882, 'alpha': 0.2581350531304493, 'gamma': 2.962052454649564, 'n_estimators': 427}. Best is trial 12 with value: -0.7476195085821928.\n",
      "[I 2025-03-11 11:40:29,884] Trial 16 finished with value: -0.6306778613235693 and parameters: {'learning_rate': 0.06059272833741182, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.6043228402685971, 'colsample_bytree': 0.7353470024635147, 'lambda': 1.0226579268858114, 'alpha': 0.4220673158914147, 'gamma': 3.9360702097861724, 'n_estimators': 453}. Best is trial 12 with value: -0.7476195085821928.\n",
      "[I 2025-03-11 11:40:36,669] Trial 17 finished with value: -0.7831833601583973 and parameters: {'learning_rate': 0.011465987174378162, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6757699612954075, 'colsample_bytree': 0.6501792003194462, 'lambda': 3.2173595178129193, 'alpha': 1.6435165879910183, 'gamma': 3.9951830425723944, 'n_estimators': 383}. Best is trial 17 with value: -0.7831833601583973.\n",
      "[I 2025-03-11 11:40:42,252] Trial 18 finished with value: -0.6877072939940341 and parameters: {'learning_rate': 0.052091558141470165, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.794093544568319, 'colsample_bytree': 0.6452580073955323, 'lambda': 2.385902287652614, 'alpha': 1.9824327678068452, 'gamma': 1.5511395275798814, 'n_estimators': 378}. Best is trial 17 with value: -0.7831833601583973.\n",
      "[I 2025-03-11 11:40:46,698] Trial 19 finished with value: -0.624643177557187 and parameters: {'learning_rate': 0.18072562911101175, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6805023290058245, 'colsample_bytree': 0.6973688671482295, 'lambda': 0.03244351333717149, 'alpha': 3.4112941950903175, 'gamma': 4.189481495052927, 'n_estimators': 336}. Best is trial 17 with value: -0.7831833601583973.\n",
      "[I 2025-03-11 11:40:49,699] Trial 20 finished with value: -0.6806037730932957 and parameters: {'learning_rate': 0.24232383975982566, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.5540517618987828, 'colsample_bytree': 0.6093706470434751, 'lambda': 0.6576619206870671, 'alpha': 0.8674823192389234, 'gamma': 3.918753421664476, 'n_estimators': 245}. Best is trial 17 with value: -0.7831833601583973.\n",
      "[I 2025-03-11 11:40:57,060] Trial 21 finished with value: -0.7854519944459648 and parameters: {'learning_rate': 0.010113923210076951, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.644270981307734, 'colsample_bytree': 0.5352614550851809, 'lambda': 4.729957894113733, 'alpha': 4.184179216889994, 'gamma': 3.0488987062639348, 'n_estimators': 440}. Best is trial 21 with value: -0.7854519944459648.\n",
      "[I 2025-03-11 11:41:03,024] Trial 22 finished with value: -0.6944006561377881 and parameters: {'learning_rate': 0.03970934584125015, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.6408857574215514, 'colsample_bytree': 0.5540033203850736, 'lambda': 2.608838200739768, 'alpha': 3.617212920660488, 'gamma': 2.9538597246379723, 'n_estimators': 409}. Best is trial 21 with value: -0.7854519944459648.\n",
      "[I 2025-03-11 11:41:08,899] Trial 23 finished with value: -0.6835808124400533 and parameters: {'learning_rate': 0.0774975471584791, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.6711471844742048, 'colsample_bytree': 0.6140865153555866, 'lambda': 4.289025974075715, 'alpha': 6.14334457298619, 'gamma': 2.944322431954528, 'n_estimators': 432}. Best is trial 21 with value: -0.7854519944459648.\n",
      "[I 2025-03-11 11:41:14,849] Trial 24 finished with value: -0.7032662888585081 and parameters: {'learning_rate': 0.03321269140563447, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.5647338406387696, 'colsample_bytree': 0.539476957172073, 'lambda': 1.4049261327128588, 'alpha': 0.6835168286216106, 'gamma': 3.9272053705983416, 'n_estimators': 381}. Best is trial 21 with value: -0.7854519944459648.\n",
      "Best Parameters: {'learning_rate': 0.010113923210076951, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.644270981307734, 'colsample_bytree': 0.5352614550851809, 'lambda': 4.729957894113733, 'alpha': 4.184179216889994, 'gamma': 3.0488987062639348, 'n_estimators': 440}\n",
      "Multiclass Model saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import helper_functions as hf\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "import numpy as np\n",
    "from constants import rv_features, rv_target\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "log_loss_scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'num_class': 5\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params, random_state=100)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "    cv_scores = cross_val_score(model, X, y, scoring=log_loss_scorer, cv=kf)\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "multiclass_study = optuna.create_study(direction='minimize')\n",
    "multiclass_study.optimize(objective, n_trials=25)\n",
    "\n",
    "multiclass_best_params = multiclass_study.best_params\n",
    "multiclass_model = xgb.XGBClassifier(**multiclass_best_params, random_state=100, num_class=5)\n",
    "multiclass_model.fit(X, y)\n",
    "\n",
    "print(f\"Best Parameters: {multiclass_best_params}\")\n",
    "\n",
    "joblib.dump(multiclass_model, 'multiclass_model.pkl')\n",
    "\n",
    "print(\"Multiclass Model saved!\")\n"
   ]
  }
 ]
}